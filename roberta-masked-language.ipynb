{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import logging\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sometimes models place special characters in front of words.   we don't need them.\n",
    "def remove_starting_character(options, starting_char):\n",
    "        new_predictions = list()\n",
    "        for prediction in options:\n",
    "            if prediction[0] == starting_char:\n",
    "                new_prediction = prediction[1:]\n",
    "                new_predictions.append(new_prediction)\n",
    "            else:\n",
    "                new_predictions.append(prediction)\n",
    "        return new_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaForMaskedLM, RobertaTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model2 = RobertaForMaskedLM.from_pretrained('roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(st):\n",
    "    input_ids = torch.tensor(tokenizer.encode(st)).unsqueeze(0) \n",
    "    outputs = model2(input_ids, masked_lm_labels=input_ids)\n",
    "    loss, prediction_scores = outputs[:2]\n",
    "    text = ''\n",
    "    for i in range(1, prediction_scores.shape[1]-1):\n",
    "        t = np.argmax(prediction_scores[0, i].tolist())\n",
    "        options = tokenizer.convert_ids_to_tokens([t])\n",
    "        options = remove_starting_character(options, \"Ä \")\n",
    "        text = text+ ' '+options[0]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he went to the farmer 's market and saw a bunch of green beans\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"he went to the farmer's <mask> and <mask> a bunch of green <mask>\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " they went to the farmer 's market and bought a bunch of hot dogs\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"they went to the farmer's <mask> and <mask> a bunch of hot <mask>\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " John was a bad spell er\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"John were a bad speller\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " John got in his car and then he went to the store where he b ought stuff\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"John got in <mask> car and then he went to the store where <mask> bought stuff\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " he went to the post office and purchased lots of postage stamps .\n"
     ]
    }
   ],
   "source": [
    "print(predict(\"he went to the <mask> office and purchased lots of postage stamps.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Whenever people go to the same center ,  they create a lot of problems\n"
     ]
    }
   ],
   "source": [
    "print(predict('Whenever <mask> go to the <mask> <mask>,  they create a lot of <mask>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Whenever you go to the whiskey bar , you have a lot of fun\n"
     ]
    }
   ],
   "source": [
    "print(predict('Whenever <mask> go to the whiskey <mask>,  <mask> have a lot of <mask>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Because he was a good runner , he planned to run ac ross the country\n"
     ]
    }
   ],
   "source": [
    "print(predict('Because he was a good runner, <mask> planned to <mask> across the <mask>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " He sailed ac ross the ocean .\n"
     ]
    }
   ],
   "source": [
    "print(predict('He  <mask> across the ocean.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " There are many people in New York city\n"
     ]
    }
   ],
   "source": [
    "print(predict('There are many people in <mask> York city'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " New York is a city full of people\n"
     ]
    }
   ],
   "source": [
    "print(predict('New <mask> is a city full of people'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following small experiment show how to draw out the transformer embedding function."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "input embedding is a matrix of shape [1, 50265, 768] \n",
    "embedding is a look-up from token-_ids to vectors of length 768\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding(50265, 768, padding_idx=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em = model2.get_input_embeddings()\n",
    "print(em)\n",
    "x = em(torch.tensor([210]))\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ou = model2.get_output_embeddings()\n",
    "y = ou(x).tolist()\n",
    "z = np.argmax(y[0])\n",
    "z"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following is a demo of how to commpute attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0, 4783,  184,   16, 3417,    2]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = 'my home is Seattle'\n",
    "in_tokens = torch.tensor(tokenizer.encode(st)).unsqueeze(0) \n",
    "in_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 768])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = em(in_tokens.squeeze(0))\n",
    "r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3037,  0.0055, -0.0154,  0.0177, -0.0040,  0.0777],\n",
       "        [ 0.0055,  0.4223,  0.0042,  0.0188, -0.0081,  0.0260],\n",
       "        [-0.0154,  0.0042,  0.3387,  0.0122,  0.0103,  0.0136],\n",
       "        [ 0.0177,  0.0188,  0.0122,  0.1937,  0.0046,  0.0717],\n",
       "        [-0.0040, -0.0081,  0.0103,  0.0046,  0.3262,  0.0105],\n",
       "        [ 0.0777,  0.0260,  0.0136,  0.0717,  0.0105,  0.2116]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.mm(r, r.T)/np.sqrt(768)\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2104, 0.1562, 0.1529, 0.1581, 0.1547, 0.1678],\n",
       "        [0.1530, 0.2321, 0.1528, 0.1550, 0.1509, 0.1562],\n",
       "        [0.1532, 0.1562, 0.2183, 0.1575, 0.1572, 0.1577],\n",
       "        [0.1605, 0.1607, 0.1596, 0.1914, 0.1584, 0.1694],\n",
       "        [0.1556, 0.1550, 0.1579, 0.1570, 0.2165, 0.1579],\n",
       "        [0.1678, 0.1593, 0.1574, 0.1668, 0.1569, 0.1918]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zsoft = torch.softmax(z, 1)\n",
    "zsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0033, -0.0361,  0.0055,  ...,  0.0633,  0.0160, -0.0369],\n",
       "        [-0.0181, -0.0205, -0.0035,  ...,  0.0598,  0.0162, -0.0402],\n",
       "        [-0.0159, -0.0460,  0.0125,  ...,  0.0715,  0.0137, -0.0353],\n",
       "        [-0.0124, -0.0344,  0.0023,  ...,  0.0651,  0.0143, -0.0416],\n",
       "        [-0.0111, -0.0395, -0.0076,  ...,  0.0736,  0.0236, -0.0372],\n",
       "        [-0.0112, -0.0369,  0.0021,  ...,  0.0672,  0.0149, -0.0390]],\n",
       "       grad_fn=<MmBackward>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q =torch.mm(zsoft, r)\n",
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here is the transformer layerNorm function (my version)\n",
    "def layerNorm(x):\n",
    "    u = x.mean(-1, keepdim=True)\n",
    "    print(u)\n",
    "    print(x-u)\n",
    "    s = (x - u).pow(2).mean(-1, keepdim=True)\n",
    "    print(s)\n",
    "    x = (x - u) / torch.sqrt(s)\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
